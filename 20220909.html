<body style="background-color:#e2edfc;">

<h3>Building imagen test sets.</h3>
    <p>ESY <a href="https://twitter.com/ESYudkowsky/status/1679561414187581441">wrote</a>, "I have tried, on every imagegen since DALL-E that I got around to trying, "Eleven evil wizard schoolgirls in an archduke's library, dressed in red and black Asmodean schoolgirl uniforms, perched on armchairs and sofas" and none have drawn it well enough to use inside an online story."</p>
    <p>Edwin Chen and Scott Alexander have <a href="https://www.surgehq.ai/blog/dall-e-vs-imagen-and-evaluating-astral-codex-tens-3000-ai-bet">discussed</a> the following:</p>
    <ul>
    <li>A red cat sitting on top of a blue dog next to a purple lake, with a black pig flying in the sky</li>
    <li>A stained glass picture of a woman in a library with a raven on her shoulder with a key in its mouth</li>
    <li>An oil painting of a man in a factory looking at a cat wearing a top hat</li>
    <li>A digital art picture of a child riding a llama with a bell on its tail through a desert</li>
    <li>A 3D render of an astronaut in space holding a fox wearing lipstick</li>
    <li>Pixel art of a farmer in a cathedral holding a red basketball</li>
    </ul>

    These test various constraints all at once, where it may be more useful to break these into smaller tests.
    <ul>
    <li>Object level mastery (aka table stakes): can it draw a variety of individual nouns and actions convincingly?</li>
    <li>Object adjustments, color: Can the engine map colors to the correct objects? Can it draw objects with nonstandard colors?</li>
    <li>Object adjustments, gerrunds: Can the engine map different actions to the component objects?</li>
    <li>Compositional: Can it apply a style when one included in the prompt in natural language?</li>
    <li>Grammar: Can it correctly apply the directionality of verbs and prepositions, can it distinguish subjects and direct objects?</li>
    <li>Grammar: Can it do so when these are chained? ("an X on top of a Y that is beside a Z...")</li>
    <li>Grammar: Can it handle "in" (or related prepositions) in relevant different senses, as a way to denote the overall setting, or as a way to denote how something should be held or placed?</li>
    <li>Capacity: How many elements can you stack before it either breaks or begins to ignore some elements?</li>
    </ul>
    
    These and ESY's seem to test many of these at once, and maybe are ultimately a test of capacity.

    <p>A proper test set could be generated along each of these lanes, with a body of sample nouns, verbs, and particles, with accompanying objective questions that any mturk could judge: "Is this cat wearing lipstick?"
    It would adjust over time to rate areas of difficulty, such as livestock with the appropriate number of legs, or hands. Undoubtedly leading AI companies have extensive internal test sets with fidelity far beyond these gross categories.</p>
    
    <a href="https://sh-tsang.medium.com/review-imagenet-v2-5d2a6aa0a916">See also</a>

<h1>Decomposing Midjourney</h1>

  <p>Another approach to imagegen validation would be interpretability, examining outputs by fuzzed inputs and separating the inputs into atomic components to identify shifts in responses, decomposing prompts word by word.</p>
  <p>The below is not a thorough investigation, just a quick proof of concept that might generalize to future work if scaled.</p>
  
<h2>Begin with <a href="https://xkcd.com/936/">four random words</a>.</h2>
  <p>"shift subsider fusillade vouch"<p>
<img src="/20220909/1_shift_subsider_fusillade_vouch.png" width="512" height="512"><p>
<img src="/20220909/2_shift_subsider_fusillade_vouch.png" width="512" height="512"><p>
<img src="/20220909/3_shift_subsider_fusillade_vouch.png" width="512" height="512"><p>

  <h2>Subsets</h2>
  <p>Deconstruct into subsets to identify common and unique elements</p>
  <article>
    <h3>subsider fusillade vouch</h3><p>
    <img src="/20220909/234.png"><p>
    <h3>shift fusillade vouch</h3><p>
    <img src="/20220909/134.png"></a><p>
    <h3>shift subsider vouch</h3><p>
    <img src="/20220909/124.png"></a><p>
    <h3>shift subsider fusillade</h3><p>
    <img src="/20220909/123.png"></a>

    <h3>shift subsider</h3><p>
    <img src="/20220909/12.png"><p>
    <h3>shift fusillade</h3><p>
    <img src="/20220909/13.png"><p>
    <h3>shift vouch</h3><p>
    <img src="/20220909/14.png"><p>
    <h3>subsider fusillade</h3><p>
    <img src="/20220909/23.png"><p>
    <h3>subsider vouch</h3><p>
    <img src="/20220909/24.png"><p>
    <h3>fusillade vouch</h3><p>
    <img src="/20220909/34.png"><p>

    <h3>shift</h3><p>
    <img src="/20220909/1.png"><p>
    <h3>subsider</h3><p>
    <img src="/20220909/2.png"><p>
    <h3>fusillade</h3><p>
    <img src="/20220909/3.png"><p>
    <h3>vouch</h3><p>
    <img src="/20220909/4.png"><p>
  </article>

<!-- Conclusion -->
<h3>Conclusion</h3><p>
  <p>Some initial patterns emerge. Fusillade is associated with more violent imagery. Vouch seems to be associated with a young woman. Red and a grayish-blue are dominant colors here, but it's not entirely clear where they come from, they show up across the subsets (perhaps fusillade most strongly, which makes some sense--maybe there's cross pollination from recent generations?). The machine seems to associate some of these random word combos with album titles ("fusillade vouch"), placing stylized words over art reminiscent of an album. I'm a little amazed midjourney wrote these words as well as it did, it generally struggles with text.<p>
    This type of decompositional analysis will likely have mixed results--some obivous results, and then a wall of incomprehensibility where it's difficult to deconstruct further. Elements with clear semantic implications will have an impact on the image in expected ways. Abstract words or word combinations will unearth hallucinations with an alien consistency that are hard to further analyze.</p>

<!-- Further research -->
<h3>Further research</h3>
<p>Examination of a few hundred more examples may reveal other subtle trends. This research would be easy to automate for generation, albeit slow, but human anaylsis (searching for common elements) would be difficult to reliably scale, since it's not obvious what to look for. Mechanical turk or (image to text classifiers as they mature) asking reviewers to tag images with elements, moods, colors, or styles could generate a dataset highlighting additional associations at scale.</p>

<p>Generating a grid of the common sets of 100 nouns and 100 adjectives, or noun-verb, or adverb-verb pairs could make it easy to track patterns that emerge from the data.</p>
<p>As imagegen quickly scales, there will be new opportunities to identify implicit features in new models, but the use of abstract terms will become more critical as the generations become more faithful to the inputs.</p>
    
</body>
